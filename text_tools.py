import asyncio
from time import monotonic
from contextlib import asynccontextmanager

from pytest_asyncio.plugin import pytest
import pymorphy2
import string
import requests


def _clean_word(word):
    word = word.replace('«', '').replace('»', '').replace('…', '')
    # FIXME какие еще знаки пунктуации часто встречаются ?
    word = word.strip(string.punctuation)
    return word


@asynccontextmanager
async def split_by_words(morph, text):
    """Учитывает знаки пунктуации, регистр и словоформы, выкидывает предлоги."""
    start = monotonic()
    words = []
    for word in text.split():
        cleaned_word = _clean_word(word)
        normalized_word = morph.parse(cleaned_word)[0].normal_form
        if len(normalized_word) > 2 or normalized_word == 'не':
            words.append(normalized_word)
        if monotonic() - start > 3:
            raise asyncio.exceptions.TimeoutError
    yield words


@pytest.mark.asyncio
async def test_split_by_words():
    # Экземпляры MorphAnalyzer занимают 10-15Мб RAM т.к. загружают в память много данных
    # Старайтесь организовать свой код так, чтоб создавать экземпляр MorphAnalyzer заранее и в единственном числе
    morph = pymorphy2.MorphAnalyzer()

    async with split_by_words(morph, 'Во-первых, он хочет, чтобы') as res:
        assert res == ['во-первых', 'хотеть', 'чтобы']

    async with split_by_words(morph, '«Удивительно, но это стало началом!»') as res:
        assert res == ['удивительно', 'это', 'стать', 'начало']

    response = requests.get('https://dvmn.org/media/filer_public/51/83/51830f54-7ec7-4702-847b-c5790ed3724c/gogol_nikolay_taras_bulba_-_bookscafenet.txt')
    response.raise_for_status()
    with pytest.raises(asyncio.exceptions.TimeoutError):
        async with split_by_words(morph, response.text) as res:
            pass


def calculate_jaundice_rate(article_words, charged_words):
    """Расчитывает желтушность текста, принимает список "заряженных" слов и ищет их внутри article_words."""

    if not article_words:
        return 0.0

    found_charged_words = [word for word in article_words if word in set(charged_words)]

    score = len(found_charged_words) / len(article_words) * 100

    return round(score, 2)


def test_calculate_jaundice_rate():
    assert -0.01 < calculate_jaundice_rate([], []) < 0.01
    assert 33.0 < calculate_jaundice_rate(['все', 'аутсайдер', 'побег'], ['аутсайдер', 'банкротство']) < 34.0
